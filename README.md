# Exercice de Programmation
## Classification d'Images de Chiens, Chats et Oiseaux avec un CNN

### 1. Pr√©paration des donn√©es
- T√©l√©chargement des images brutes depuis https://www.kaggle.com/datasets/swaroopkml/cifar10-pngs-in-folders?resource=download
- Dossier /train :
  - 5000 photos / cat√©gorie
  - utilis√© pour l'entrainement et la validation (80/20) 
- Dossier /test :
  - 1000 photos / cat√©gorie
  - utilis√© pour les tests
- Extraction des sous-dossiers n√©cessaires : /dog, /cat, /bird

### 2. Pr√©traitement des Images
- Utilisation de ImageDataGenerator() pour 
  - la normalisation des images
  - la s√©paration entrainement / validation
- TODO: Si n√©cessaire augmenter virtuellement le nombre d'images par des transformation (flip, roration)

### 3. Cr√©ation du Mod√®le CNN
- Fichier : 3.CNN-Projet1-model-tf.py
- Mod√®le Sequential Keras
- Compilation avec 
  - perte par cross-entropie cat√©gorielle
  - optimizer = Adam
  - metrics = Accuracy
- Entrainement avec Early Stop:
  - patience = 2 pour attendre 2 epoch avant de stopper
  - restore_best_weights pour revenir au meilleur score
  - R√©sultats V1: Best Epoch = 7, Accuracy = 2e-04 ü•π 
- Visualisation graphique / epoch
  - perte √† l'entra√Ænement
  - perte au test
- Sauvegarde du mod√®le

### 4. Visualisation des Couches Convolutionnelles
- Dossier /v1
- maps-- + nom de la couche
- Exemple :
  - ![maps--model_cnn_cifar10-conv2d.png](tf_models%2Fv1%2Fmaps--model_cnn_cifar10-conv2d.png)
- features_map-- + nom de la couche
- Exemple
  - ![feature_maps--model_cnn_cifar10-conv2d.png](tf_models%2Fv1%2Ffeature_maps--model_cnn_cifar10-conv2d.png)

### 5. √âvaluation et Test
- Fichier : 3.CNN-Projet1-test-tf.py
- R√©sultats Version 1 :
  - Evaluation mauelle : 4 pass√©s / 8 tests ü•π
  - Evaluation automatique avec jeu de test : 
    - Pr√©cision = 11% üò≠

### 6. Am√©lioration
- V2.1 :
  - Ajout d'images virtuellement par augmentation :
    - RandomFlip("horizontal_and_vertical")
    - RandomRotation(0.2)
  - Augmentation Epoque : 50 (avec toujours le early stop)
  - R√©sultats Version 2.1 : 
    - 68% ü•π
- V2.2 :
  - Suppression des augmentations
  - Augmentation des couches de conv
  - Augmentation des couches de neurones
  - Ajout de couches de DropOut (apr√®s Pooling) pour mitiger l'apprentissage
- V2.3 :
  - Changement de l'optimizer par SGD
